# Supervised Machine Learning: Regression and Classification

## Week1 Introduction to Machine Learning

- [Lab1](./week1/lab1.ipynb) Python and Jupyter Notebooks
- [Lab2](./week1/lab2.ipynb) Model representation
- [Lab3](./week1/lab3.ipynb) Cost function
- [Lab4](./week1/lab4.ipynb) Gradient desent

## Week2 Regression with multiple input variables

- [Lab1](./week2/lab1.ipynb) Python, Numpy, and vectorization
- [Lab2](./week2/lab2.ipynb) Multiple linear regression
- [Lab3](./week2/lab3.ipynb) Feature scaling and Learning Rate
- [Lab4](./week2/lab4.ipynb) Feature engineering and Polynomial regression
- [Lab5](./week2/lab5.ipynb) Linear regression with scikit-learn

## Week3 Classification

- [Lab1](./week3/lab1.ipynb) Classification
- [Lab2](./week3/lab2.ipynb) Sigmoid function and logistic regression
- [Lab3](./week3/lab3.ipynb) Decision boundary
- [Lab4](./week3/lab4.ipynb) Logistic loss
- [Lab5](./week3/lab5.ipynb) Cost function for logistic regression
- [Lab6](./week3/lab6.ipynb) Gradient descent for logistic regression
- [Lab7](./week3/lab7.ipynb) Logistic regression with scikit-learn
- [Lab8](./week3/lab8.ipynb) Overfitting
- [Lab9](./week3/lab9.ipynb) Regularization

### [Practice Lab](./week3/lab.ipynb) logistic regression
